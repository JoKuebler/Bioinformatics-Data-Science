{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Throwback: which SNPs are associated with mouse hair color again?\n",
    "\n",
    "Remember the GWAS task, where we investigated which SNPs were significantly associated with the coat color of mice? Machine learning ties in well with this task. We know random forests are useful to determine the importance of different features when classifying samples. We could ask a random forest to predict hair color from genotype data, and then look at what features it considered important while doing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the genotype and color data. Make sure you index the genotype data explicitly by passing `index_col=\"Locus\"` to the csv reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotype = pd.read_csv(\"../data-livermito/aad0189_DataFileS4.txt\", sep=\"\\t\", comment=\"@\", index_col=\"Locus\")\n",
    "colors = pd.read_csv(\"../data-livermito/coat_color.csv\", index_col=0, names=[\"color\"], na_values='x').dropna()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the genotype data into two dataframes: one should contain the metadata (first 3 columns) and the other the actual genotype data. Call them `geno_metadata` and `geno`.\n",
    "\n",
    "Remember, `sklearn` takes samples in rows, and our samples correspond to mice strains here, so transpose `geno`. Also make sure that the indices of the `geno` and `color` DFs line up with each other: only keep the intersection of their indices. Index objects support intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the B/D/H/U genotype information with numbers. You can use -1/0/0/1 or 0/1/1/2 for B/H/U/D respectively. Either way, it's best to encode H with a value between B and D since it stands for hybrid.\n",
    "\n",
    "As for encoding colors: they are already numbers. We won't even transform them to the binary black/non-black labels like we did on day 3, we will just feed it them to the predictor as they are. Let the random forest figure out the associations for black/grey/white/brown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a random forest classifier with all the data. Make sure you use a lot of trees in that forest (a few thousand should be good) so we can get fine-grained values for feature importances. The more decision trees you run the data on, the clearer it gets which features it tests most often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take the feature importance vector, and add it to the `geno_metadata` DataFrame as a new column. Sort by that column (obviously descending), and look at the most important SNP ids. Compare them with your GWAS data -- no need to load anything, just look at the Manhattan plot from day 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you took the effort to load that mouse genotype and color data, you might as well take a peek at the performance of the predictor. Calculate a cross-validated accuracy score, and create a confusion matrix for the four colors. You can lower the number of trees used by an order of magnitude, since cross-validation makes things more time intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, create a ROC diagram. You know how to make them for binary classifiers... but this isn't a binary classification task. What should it look like when you have 4 labels instead of just 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
