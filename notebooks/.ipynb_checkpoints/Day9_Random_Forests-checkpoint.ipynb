{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forests on mouse phenotype data\n",
    "\n",
    "Today we will use one of the most popular supervised learning methods: random forests. It is an ensemble method, which means it uses multiple predictors and makes its final prediction based on a democratic vote of its individual predictors.\n",
    "\n",
    "These sub-predictors are called decision trees, hence the name forest. Decision trees are labelled binary trees. Every leaf is associated with a class label, and every branching point is a test for a feature-value pair: if the feature is larger than the value, the sample is passed on towards the left branch, otherwise it continues on the right branch. The prediction is the label of the leaf it eventually reaches, starting from the tree's root.\n",
    "\n",
    "Random forests generate a set of decision trees in a structured manner, and aggregate their results. Let's see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pd.read_csv('../example_data/phenotype_cd_hfd.csv', index_col=0)\n",
    "target = pheno['diet'].replace('CD', 0).replace('HFD', 1)\n",
    "data = pheno.dropna(axis=1).drop(columns=['strain', 'diet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Use a random forest classifier\n",
    "Initialize it with default settings. Show its biased performance by fitting and predicting on the entire dataset, and then show its real accuracy using a proper cross-validation. For cross-validation, use the one-liner form with yesterday's convencience function.\n",
    "\n",
    "Then try the same with standardized input data (no need to do it fold-by-fold), and report your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Determine the uncertainty of the accuracy by bootstrapping\n",
    "You must have noticed that the cross-validated accuracy of the model isn't exact: it depends on the particular folds that you get during cross-validation.\n",
    "If you have `shuffling` enabled, your folds will be different each time. So by repeating cross-validation many times, you could get a clearer idea of the model's accuracy by taking the average, or better yet, looking at the distribution of the individual accuracy figures.\n",
    "\n",
    "Use 100 repeats and plot the histogram of the resulting accuracy values. What is the 90% confidence interval of the model's accuracy? (What is a confidence interval to begin with?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Extract prediction probabilities instead of labels\n",
    "`RandomForestClassifier`s have a `predict_proba` method by default, similar to `SVC`s with `proability=True` turned on. Use the convencience one-liner to get cross-validated class membership probability estimates for each sample. Create a histogram using the probability values for class `1`, but separate them by the true label of the samples, and color the two labels differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Look at the numeric probability values. Why are they so rough?\n",
    "Find out what they are derived from, and try to increase their resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Create a ROC curve\n",
    "Now that you know how to access the continuous internal prediction variables (class membership probability in this case) you can create a ROC plot easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Visualize a decision tree\n",
    "Pick any decision tree from the random forest, export it in `DOT` format using `sklearn.tree.export_graphviz` and visualize it with an online tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Feature importances\n",
    "Random forests utilize their internal structure not just to provide probability estimates, but also to estimate the importance of different features. How do you think it's done? Find a way to access the values, and present them on a bar plot, sorted by importance.\n",
    "\n",
    "By the way, do you have to use cross-validation for feature importance estimates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Choose 3 features, and evaluate the model using only those features\n",
    "Try to choose them with accuracy in mind. Treat it as a challenge: which 3 to choose to get the best model? What was your strategy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Feature clustering\n",
    "Plot a clustermap of your data: it's not too big, 113x55 so you can keep all rows and columns and still have a readable figure with all feature labels if you increase its width a bit.\n",
    "\n",
    "Should you plot the raw or the normalized data?\n",
    "\n",
    "What patterns do you see? Are they relevant to the previous task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7.2 Feature correlations\n",
    "Calculate correlations between your features, and visualize them on a heatmap. Would it be useful to include the diet as an extra column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
